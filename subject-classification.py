# -*- coding: utf-8 -*-
"""proyekPertamaNLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OPpmVIXnlOJMU-ZX31dESkGYHDA7Utc9

1. Nama : Sri Kresna Maha Dewa
2. email : srikresna383@gmail.com
3. TTL : Sidoarjo, 03 Agustus 2003
4. Instansi : Politeknik Negeri Malang
"""

!pip install -q kaggle

from google.colab import files
files.upload()

!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d mrutyunjaybiswal/iitjee-neet-aims-students-questions-data

!unzip iitjee-neet-aims-students-questions-data.zip

import pandas as pd

df = pd.read_csv('subjects-questions.csv')
df

#one hot encoding
category = pd.get_dummies(df.Subject)
df_baru = pd.concat([df, category], axis = 1)
df_baru = df_baru.drop(columns = 'Subject')

df_baru

df_baru['eng'] = df_baru['eng'].str.lower()
length = df['eng'].str.len().max()
df_baru.columns

#ubah menjadi numpy array
news = df_baru['eng'].values
label = df_baru[['Biology', 'Chemistry', 'Maths', 'Physics']].values
label

#pisahkan menjadi train & test
from sklearn.model_selection import train_test_split
news_train, news_test, label_train, label_test = train_test_split(news, label, test_size = 0.2, random_state = 123)

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

#tokenisasi
tokenizer = Tokenizer(num_words = length, oov_token = '', filters='!"#$%&()*+,-./:;<=>@[\]^_`{|}~ ')
tokenizer.fit_on_texts(news_train)
tokenizer.fit_on_texts(news_test)

sequences_train = tokenizer.texts_to_sequences(news_train)
sequences_test = tokenizer.texts_to_sequences(news_test)

padded_train = pad_sequences(sequences_train)
padded_test = pad_sequences(sequences_test)

import tensorflow as tf

#bangun model
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=5000, output_dim=16),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(4, activation='softmax')
])

#compile

model.compile(loss ='categorical_crossentropy',
              optimizer = 'adam',
              metrics = ['accuracy'])

#cek model

model.summary()

from tensorflow.keras.callbacks import Callback, ReduceLROnPlateau, EarlyStopping

#Callback Function
class accCallback(Callback):
   def on_epoch_end(self, epoch, logs={}):
        if(logs.get('accuracy') >= 0.90 and logs.get('val_accuracy') >= 0.90):
            print("\nAccuracy and Val_Accuracy has reached 90%!", "\nEpoch: ", epoch)
            self.model.stop_training = True

callbacks = accCallback()

auto_reduction_LR = ReduceLROnPlateau(
    monitor = 'val_accuracy',
    patience = 2, #setelah 2 epoch, jika tidak ada kenaikan maka LR berkurang
    verbose = 1,
    factor = 0.2,
    min_lr = 0.000003
)

auto_stop_learn = EarlyStopping(
    monitor = 'val_accuracy',
    min_delta = 0,
    patience = 4,
    verbose = 1,
    mode = 'auto' 
)

#latih model
history = model.fit(padded_train, label_train,
                    steps_per_epoch = 30,
                    epochs = 100,
                    validation_data = (padded_test, label_test),
                    verbose = 1,
                    validation_steps = 50,
                    callbacks=[callbacks, auto_reduction_LR, auto_stop_learn], 
                    )

#plotting
import pandas as pd
import matplotlib.pyplot as plt
pd.DataFrame(history.history).plot(figsize=(7, 4))
plt.grid(True)
plt.gca().set_ylim(0,3) #sumbu y

plt.show()